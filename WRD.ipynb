{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\UsersDocs\\\\Mkhalifa\\\\Desktop\\\\UDACITY\\\\Project We Rate dogs\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter-archive-enhanced-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  requests library \n",
    "url=\"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('image_predictions.tsv', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "    \n",
    "image_predictions = pd.read_csv('image_predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'MY CONSUMER KEY'\n",
    "consumer_secret = 'MY CONSUMER SECRET'\n",
    "access_token = 'MY ACCESS TOKEN'\n",
    "access_secret = 'MY ACCESS SECRET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_json.txt', 'a', encoding='utf8') as f:\n",
    "    for tweet_id in twitter_archive['tweet_id']:\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            json.dump(tweet._json, f)\n",
    "            f.write('\\n')\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = []\n",
    "\n",
    "tweet_file = open('tweet_json.txt', \"r\")\n",
    "\n",
    "for line in tweet_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "tweet_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info['id'] = list(map(lambda tweet: tweet['id'], tweets_data))\n",
    "tweet_info['retweet_count'] = list(map(lambda tweet: tweet['retweet_count'], tweets_data))\n",
    "tweet_info['favorite_count'] = list(map(lambda tweet: tweet['favorite_count'], tweets_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive.text.str.contains('&amp;')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.name.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.loc[(twitter_archive['name'].str.islower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.loc[(twitter_archive['name'].str.islower()) & (twitter_archive['text'].str.contains('named'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.loc[(twitter_archive['name'].str.islower()) & (twitter_archive['text'].str.contains('name is'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omaly func' \n",
    "twitter_archive[twitter_archive.name == \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View row of specific tweet using tweet_id of a tweet that doesn't have a rating \n",
    "twitter_archive[twitter_archive.tweet_id == 810984652412424192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of original DataFrames to work off of\n",
    "twitter_archive_clean = twitter_archive.copy()\n",
    "image_predictions_clean = image_predictions.copy()\n",
    "tweet_info_clean = tweet_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'dog_stage' variable which is made by extracting the dog stage variables from the text column when available \n",
    "twitter_archive_clean['dog_stage'] = twitter_archive_clean['text'].str.extract('(puppo|pupper|floofer|doggo)', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable of columns that are no longer needed and drop them from the DataFrame \n",
    "columns = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "twitter_archive_clean = twitter_archive_clean.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "twitter_archive_clean.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = pd.merge(left=twitter_archive_clean, right=tweet_info_clean, left_on='tweet_id', right_on='id', how='inner')\n",
    "twitter_archive_clean = twitter_archive_clean.merge(image_predictions_clean, on='tweet_id', how='inner')\n",
    "twitter_archive_clean = twitter_archive_clean.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean.dropna(subset=['expanded_urls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(twitter_archive_clean['expanded_urls'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean[twitter_archive_clean['retweeted_status_id'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp']\n",
    "twitter_archive_clean = twitter_archive_clean.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "named_to_replace = twitter_archive_clean.loc[(twitter_archive_clean['name'].str.islower()) & (twitter_archive_clean['text'].str.contains('named'))]\n",
    "name_is_to_replace = twitter_archive_clean.loc[(twitter_archive_clean['name'].str.islower()) & (twitter_archive_clean['text'].str.contains('name is'))]\n",
    "not_named_to_replace = twitter_archive_clean.loc[(twitter_archive_clean['name'].str.islower())]\n",
    "\n",
    "# Save these locations as lists\n",
    "named_to_replace_list = named_to_replace['text'].tolist()\n",
    "name_is_to_replace_list = name_is_to_replace['text'].tolist()\n",
    "not_named_to_replace_list = not_named_to_replace['text'].tolist()\n",
    "\n",
    "# For loop to iterate through locations where name is lowercase and the words 'named' appear in 'text' and set the 'name' \n",
    "# value to be the word that appears after 'named'\n",
    "for entry in named_to_replace_list:\n",
    "    mask = twitter_archive_clean.text == entry\n",
    "    name_column = 'name'\n",
    "    twitter_archive_clean.loc[mask, name_column] = re.findall(r\"named\\s(\\w+)\", entry)\n",
    "\n",
    "# For loop to iterate through locations where name is lowercase and the words 'name is' appear in 'text' and set the 'name' \n",
    "# value to be the word that appears after 'name is'    \n",
    "for entry in name_is_to_replace_list:\n",
    "    mask = twitter_archive_clean.text == entry\n",
    "    name_column = 'name'\n",
    "    twitter_archive_clean.loc[mask, name_column] = re.findall(r\"name is\\s(\\w+)\", entry)    \n",
    "\n",
    "# For loop to iterate through locations where name is lowercase and replace the name value with the word \"None\"\n",
    "for entry in not_named_to_replace_list:\n",
    "    mask = twitter_archive_clean.text == entry\n",
    "    name_column = 'name'\n",
    "    twitter_archive_clean.loc[mask, name_column] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "twitter_archive_clean.name = twitter_archive_clean.name.replace(\"O\", \"O'Malley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.name.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.loc[(twitter_archive_clean['name'].str.islower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.name == \"O'Malley\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['name'] = twitter_archive_clean['name'].replace('None', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all occurences where there are more than one #/# in 'text' column\n",
    "twitter_archive_clean[twitter_archive_clean.text.str.contains( r\"(\\d+\\.?\\d*\\/\\d+\\.?\\d*\\D+\\d+\\.?\\d*\\/\\d+\\.?\\d*)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the text where the rating numerator and denominators were incorrectly extracted\n",
    "ratings_to_fix = ['After so many requests, this is Bretagne. She was the last surviving 9/11 search dog, and our second ever 14/10. RIP https://t.co/XAVDNDaVgQ', \n",
    " 'Happy 4/20 from the squad! 13/10 for all https://t.co/eV1diwds8a', \n",
    " 'This is Bluebert. He just saw that both #FinalFur match ups are split 50/50. Amazed af. 11/10 https://t.co/Kky1DPG4iq', \n",
    " 'This is Darrel. He just robbed a 7/11 and is in a high speed police chase. Was just spotted by the helicopter 10/10 https://t.co/7EsP8LmSp5',\n",
    " 'This is an Albanian 3 1/2 legged  Episcopalian. Loves well-polished hardwood flooring. Penis on the collar. 9/10 https://t.co/d9NcXFKwLv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for entry in ratings_to_fix:\n",
    "    mask = twitter_archive_clean.text == entry\n",
    "    column_name1 = 'rating_numerator'\n",
    "    column_name2 = 'rating_denominator'\n",
    "    twitter_archive_clean.loc[mask, column_name1] = re.findall(r\"\\d+\\.?\\d*\\/\\d+\\.?\\d*\\D+(\\d+\\.?\\d*)\\/\\d+\\.?\\d*\", entry)\n",
    "    twitter_archive_clean.loc[mask, column_name2] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.text.isin(ratings_to_fix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change datatype of rating_numerator and denominator to float\n",
    "twitter_archive_clean['rating_numerator'] = twitter_archive_clean['rating_numerator'].astype('float')\n",
    "twitter_archive_clean['rating_denominator'] = twitter_archive_clean['rating_denominator'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set correct numerators for specific tweets\n",
    "twitter_archive_clean.loc[(twitter_archive_clean['tweet_id'] == 883482846933004288) & (twitter_archive_clean['rating_numerator'] == 5), ['rating_numerator']] = 13.5\n",
    "twitter_archive_clean.loc[(twitter_archive_clean['tweet_id'] == 786709082849828864) & (twitter_archive_clean['rating_numerator'] == 75), ['rating_numerator']] = 9.75\n",
    "twitter_archive_clean.loc[(twitter_archive_clean['tweet_id'] == 778027034220126208) & (twitter_archive_clean['rating_numerator'] == 27), ['rating_numerator']] = 11.27\n",
    "twitter_archive_clean.loc[(twitter_archive_clean['tweet_id'] == 680494726643068929) & (twitter_archive_clean['rating_numerator'] == 26), ['rating_numerator']] = 11.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean[twitter_archive_clean.tweet_id != 810984652412424192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.tweet_id == 810984652412424192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['text'] = twitter_archive_clean['text'].str.replace('&amp;', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean[twitter_archive_clean.text.str.contains('&amp;')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove url from sources\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].str.replace('<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'Twitter for iPhone')\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].str.replace('<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>', 'Vine')\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].str.replace('<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>', 'Twitter Web Client')\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].str.replace('<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>', 'TweetDeck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype to category\n",
    "twitter_archive_clean['source'] = twitter_archive_clean['source'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['dog_stage'] = twitter_archive_clean['dog_stage'].astype('category')\n",
    "twitter_archive_clean['timestamp'] = pd.to_datetime(twitter_archive_clean['timestamp'])\n",
    "twitter_archive_clean['tweet_id'] = twitter_archive_clean['tweet_id'].astype('str')\n",
    "twitter_archive_clean['in_reply_to_status_id'] = twitter_archive_clean['in_reply_to_status_id'].astype('str')\n",
    "twitter_archive_clean['in_reply_to_user_id'] = twitter_archive_clean['in_reply_to_user_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean DataFrame to csv file\n",
    "twitter_archive_clean.to_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of twitter_archive_clean to work off of using only my variables of interest\n",
    "time_df = twitter_archive_clean[['timestamp', 'retweet_count', 'favorite_count', 'rating_numerator', 'rating_denominator']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to be the timestamp so time is displayed properly in plots\n",
    "time_df.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rating_ration variable \n",
    "\n",
    "time_df['rating_ratio'] = time_df['rating_numerator']/time_df['rating_denominator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['retweet_count'].plot(color = 'red', label='Retweets')\n",
    "time_df['favorite_count'].plot(color = 'blue', label='Favorites')\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Tweet timestamp')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Retweets and favorites over time')\n",
    "plt.savefig('retweets_favorites.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['rating_ratio'].plot()\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Ratio')\n",
    "plt.title('Rating ratio over time')\n",
    "plt.savefig('ratio.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Limit y axis to zoom in on data and ignore outliers\n",
    "time_df['rating_ratio'].plot()\n",
    "plt.ylim(-1, 3)\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Ratio')\n",
    "plt.title('Rating ratio over time')\n",
    "plt.savefig('ratio_zoom.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
