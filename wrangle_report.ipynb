{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following report I will explain my wrangling efforts in more detail. Shortly before that I would like to briefly describe which data I wrangled. The data that was wrangled by me is the tweet archive of Twitter user@dog_rated, also known as WeRateDogs. To begin with, all the data I need must be collected. I may need to download a file from the internet, scraping a web page or querying an API, etc. That depends on where it's stored. In my task there were a total of three separate sources ('Enhanced Twitter Archive', 'Image_Prediction' and 'Additional Data via Twitter API'). After collecting the data, I deal with it to know what data is in front of me. Afterwards I have to import that data into my programming environment. In my case it is the Jupyter Notebook. So I have now collected all the data and added it to my Jupyter Notebook. That was the first step, called 'Gather'. The second step means 'Assess'. In this step, the whole dataframes are evaluated. Either visually by observing or programmatically by using codes. This means that quality problems and imperfections can be easily identified and noted. At the beginning I did the whole thing visually to get an overview and to see where inaccuracies can be found. I then worked with Python codes, which consequently proved my observations to me. Finally, I summarized all quality problems and tidiness problems in individual steps and prepared my tasks for the next step. In the last step 'Clean', the points that were recognized as a problem and noted during 'Gather' are processed. That means I tried to solve the problems and leave the dataframe as clean as possible. The quality problems as well as imperfections are also fixed by Python codes. After these steps, the dataframe is ready to do reasoning and visualization because it is now easier and more orderly for the viewer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
